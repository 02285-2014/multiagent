\documentclass[11pt]{report}
\usepackage{graphicx}
\usepackage{titling}
\usepackage{fancyhdr}
\usepackage[latin1]{inputenc}
\usepackage{enumerate}
\usepackage{float}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage[labelfont=bf]{caption}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{listings}
\usepackage{pdflscape}
\usepackage[a4paper]{geometry}
\usepackage{tabu}
\usepackage{longtable}
\usepackage{xcolor}
\usepackage{colortbl}
\parindent=0pt
\frenchspacing

\pagestyle{fancy}

\fancyhead[L]{\slshape\footnotesize March 11, 2014\\ ${}$\\\textsc{Artificial Intelligence and Multi-agent systems}}
\fancyhead[R]{\slshape\footnotesize \textsc{Andreas Kjeldsen (s092638)}\\\textsc{Morten Eskesen (s133304)}\\\textsc{Peter Carlslund (s113998)}}
\fancyfoot[C]{\thepage}

\newcommand{\tab}{\hspace*{2em}}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\begin{document}

\begin{titlepage}
\begin{center}

\includegraphics[scale=2.0]{../GFX/dtu_logo.pdf}\\[1cm]

\textsc{\LARGE Technical University of Denmark}\\[1.5cm]

\textsc{\Large 02285 Artificial Intelligence and Multi-agent Systems}\\[0.5cm]

% Title
\HRule \\[0.4cm]
{\huge \bfseries Mandatory Assignment 1}\\[0.1cm]
\HRule \\[1.5cm]

% Author and supervisor
\large
\emph{Authors:}
\\[10pt]
Andreas Hallberg \textsc{Kjeldsen}\\
\emph{s092638@student.dtu.dk}
\\[10pt]
Morten Chabert \textsc{Eskesen}\\
\emph{s133304@student.dtu.dk}
\\[10pt]
Peter \textsc{Carlslund}\\
\emph{s113998@student.dtu.dk}

\vfill

% Bottom of the page
{\large March 11, 2014}

\end{center}
\end{titlepage}

${}$
\section*{Introduction}
This assignment is about path finding in a randomly generated environment. The assignment is an introduction to a larger project with multi-agents.

\section*{Problem Analysis}
Being able to find paths in a known environment is easy. However if an agent is dropped into an unknown environment you have to map the environment first in order to be able to find paths in the environment. The most interesting part of this problem is exactly that.\\
\\
There are multiple ways of mapping an unexplored environment, the problem is how do you do it efficiently. There are certain limitations to the mapping process:
\begin{itemize}
	\item When moving from one spot to another, we do not know what direction we went.
	\item We do not know how the spots are located in relation to other spots, just that two spots have a path between them.
	\item We can only see territory that are at most two 'spots' away.
\end{itemize}
While mapping we should also remember how cumbersome it was to travel from one spot to another and also remember if the spots had valuable resources.\\
\\
To overcome the challenge of mapping the unexplored environment with the limitations stated above, we need to solve three subproblems: How to map the environment, decide in which order we should gather information, how to plan our actions and how to plan a route from one spot to another.

\section*{Solution}
\subsection*{Mapping}
We start by creating an empty graph, then we add the currently visible vertices and edges to it. We use breadth first search for figuring out which vertex to visit next, this is because we disregard the edge weight and just want to find the closest possible unexplored vertex. Whenever we reach a vertex, we add any new vertices and edges that are now visible. We continue this way until the whole environment has been mapped, which we claim it has been whenever we do not know of any unvisited vertices.

\subsection*{Gathering Information}
Each vertex has a value and each edge has a cost. These values are not known simply  by being able to see the vertex or edge. The vertices has to be probed and the edges has to be surveyed. Probing and surveying are separate actions. When we reach a vertex that we haven't probed, we probe it. When positioned at a vertex that has one or more edge that are unsurveyed, we survey them.

\subsection*{Action Planning}
Our agent supports the following actions: {\tt Recharge, Probe, Survey, GoTo, Skip}. The {\tt Probe} and {\tt Survey} actions are used for gathering information. The {\tt GoTo} action is used for moving the agent to another vertex. The {\tt Recharge} action is used when we're low on energy. Our agent consumes energy when performing actions, therefore it's important to keep track of how much energy is left and recharge when required. We claim that a recharge is necessary when there are $\frac{1}{3}$ energy left. We also make the agent recharge fully, meaning more than one recharge action might be required. We only use the {\tt Skip} action as a fallback action, meaning it will only be chosen if no other action is chosen and the agent is fully charged.\\
\\
Which action to be chosen is checked for in the following hierarchical order: {\tt Recharge, Probe, Survey, GoTo, Skip}. This ensures that our agent gets recharged and that it does not move to another vertex without first gathering all possible information from the vertex it is currently positioned at.

\subsection*{Path Planning}
While mapping, our agent should be able to take instructions about where to go. When receiving an instruction, the agent uses Dijkstra's algorithm to plan the path to the goal vertex. \textbf{HEURISTIC SHIT HERE!}.\\
\\
While moving towards the goal vertex, new vertices and edges are still probed and surveyed. If the goal node has not been seen, the agent keep on mapping, but notifies when the goal node has been found.

\section*{Results}
Our agent is able to properly map an unknown environment, though as of right now we cannot make any guarantees regarding the time it takes to map the environment. When the environment has been mapped, our agent will recharge fully and then stand still until further instructions are send to it, this might not be the perfect way to behave, but we can disregard the opposing team for the moment and therefore an idle agent is okay.\\
\\
Our agent is also able to plan a path to a specific node and follow the path afterwards. The heuristic used could possibly be improved by somehow transforming the graph into a real map with coordinates, that would allow us to use metric distances between vertices in our heuristics.\\
\\
We've been experiencing some unusual behavior when running our agent. Sometimes our agent would try to go to the same vertex it was already located at, this is because even though it's first {\tt GoTo} action was successful, the server does not indicate that in the response. We've determined that the server responses are one turn behind. We've been notified that we're not the only group experiencing this unusual behavior.

\end{document}
